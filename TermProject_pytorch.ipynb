{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TermProject_pytorch",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1i6sREAVmFbryqHgvFGvpr_dAsBwZLIJL",
      "authorship_tag": "ABX9TyPsFizx0XQ41JxVxLXLr/Aq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c40bc380dffc42dcbe9f1263746bcc11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f0255bbf1b94c1b92d6e7466a848466",
              "IPY_MODEL_f96dbc4405d441768c29d596f02f3942",
              "IPY_MODEL_218fc50b8fcc41c3ba23fadc2900ab27"
            ],
            "layout": "IPY_MODEL_b89fc5c0c2da4dfa975494cbe259f9bb"
          }
        },
        "7f0255bbf1b94c1b92d6e7466a848466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_657f4b85112b4fe38dacd33de959d777",
            "placeholder": "​",
            "style": "IPY_MODEL_6b41d13620de492a85f42ceee059eaf1",
            "value": ""
          }
        },
        "f96dbc4405d441768c29d596f02f3942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd40572e43804ec4b6c943a5ecccc6d3",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af91c0d47bfd4d6ca6c9eee1713a77a2",
            "value": 170498071
          }
        },
        "218fc50b8fcc41c3ba23fadc2900ab27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7b157359724abaac9d1a5ceba59bd2",
            "placeholder": "​",
            "style": "IPY_MODEL_653ac88d216d4631a52640e0ff5112ce",
            "value": " 170499072/? [00:02&lt;00:00, 63797017.93it/s]"
          }
        },
        "b89fc5c0c2da4dfa975494cbe259f9bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657f4b85112b4fe38dacd33de959d777": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b41d13620de492a85f42ceee059eaf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd40572e43804ec4b6c943a5ecccc6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af91c0d47bfd4d6ca6c9eee1713a77a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a7b157359724abaac9d1a5ceba59bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "653ac88d216d4631a52640e0ff5112ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wlsdn2749/CNU_AI_Teamwork/blob/main/TermProject_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA582FPIolny"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "z5isCvV4uUVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "debc3573-c722-4593-a17f-f7a38447ced0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install adamp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLZ91rS_pKuQ",
        "outputId": "39766583-2efc-40f4-dae5-1291f5544092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adamp in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade efficientnet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9iDRhs4pTy5",
        "outputId": "fc8dbcd3-80e2-483b-bcc1-0e778e3a7678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: efficientnet-pytorch in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 설정\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print('device: ', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvBPb0Pm1esU",
        "outputId": "c11ce74b-984e-4ae9-c4fe-bfa5c371d51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device:  cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  \n",
        "    torch.backends.cudnn.deterministic = True  \n",
        "    torch.backends.cudnn.benchmark = True  \n",
        "seed_everything()"
      ],
      "metadata": {
        "id": "HnjcHVqSo1DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "else: torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "dLKcyc321q4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_train = pd.read_csv('/content/drive/MyDrive/TermProject/dataset/Term_Dataset/train_data.csv')\n",
        "val = pd.read_csv('/content/drive/MyDrive/TermProject/dataset/Term_Dataset/val_data.csv')\n",
        "\n",
        "\n",
        "train = b_train.drop(b_train.columns[0], axis=1)\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0T_zR2cvpABa",
        "outputId": "7bada96a-bd06-4e1e-b308-d3c87b63faeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      file_name class\n",
              "0  img00047.png   bag\n",
              "1  img00053.png   bag\n",
              "2  img00052.png   bag\n",
              "3  img00046.png   bag\n",
              "4  img00050.png   bag"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c701f52-793b-404c-abe2-cc90fd61e9f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>img00047.png</td>\n",
              "      <td>bag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>img00053.png</td>\n",
              "      <td>bag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>img00052.png</td>\n",
              "      <td>bag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>img00046.png</td>\n",
              "      <td>bag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>img00050.png</td>\n",
              "      <td>bag</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c701f52-793b-404c-abe2-cc90fd61e9f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c701f52-793b-404c-abe2-cc90fd61e9f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c701f52-793b-404c-abe2-cc90fd61e9f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7bc_jmg1x6S",
        "outputId": "87e02c92-0895-467f-c250-522f56d9e473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lamp            126\n",
              "pot              90\n",
              "shoe             90\n",
              "bag              72\n",
              "bed              72\n",
              "chair            72\n",
              "coffeetable      72\n",
              "cup              72\n",
              "kitchentools     72\n",
              "LivingSofa       72\n",
              "laptop           54\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 확인\n",
        "sample_image = Image.open('/content/drive/MyDrive/TermProject/dataset/Term_Dataset/train' + '/' + train['file_name'][0])\n",
        "sample_label = train['class'][0]\n",
        "plt.title('class: ' + str(sample_label))\n",
        "plt.imshow(sample_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "RJpcm0dX12Es",
        "outputId": "ece6817e-56bf-4204-d6dd-3a7777b5ae9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f922c8e3310>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# CIFAR10 데이터셋 로딩 및 변환\n",
        "trainset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/TermProject/dataset/Term_Dataset/train', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "# 미니배치 처리를 위한 데이터로더 생성\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "dataiter = iter(trainloader)\n",
        "#첫번째 그룹 4개 이미지 데이터 획득\n",
        "train, label = dataiter.next()\n",
        "# 첫번째 4개 이미지의 데이터 Shape 확인\n",
        "print(train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "c40bc380dffc42dcbe9f1263746bcc11",
            "7f0255bbf1b94c1b92d6e7466a848466",
            "f96dbc4405d441768c29d596f02f3942",
            "218fc50b8fcc41c3ba23fadc2900ab27",
            "b89fc5c0c2da4dfa975494cbe259f9bb",
            "657f4b85112b4fe38dacd33de959d777",
            "6b41d13620de492a85f42ceee059eaf1",
            "cd40572e43804ec4b6c943a5ecccc6d3",
            "af91c0d47bfd4d6ca6c9eee1713a77a2",
            "7a7b157359724abaac9d1a5ceba59bd2",
            "653ac88d216d4631a52640e0ff5112ce"
          ]
        },
        "id": "m-RsDx7cbs0L",
        "outputId": "839bbe31-58c8-411b-8479-4f2c2cdc916c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/MyDrive/TermProject/dataset/Term_Dataset/train/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c40bc380dffc42dcbe9f1263746bcc11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/TermProject/dataset/Term_Dataset/train/cifar-10-python.tar.gz to /content/drive/MyDrive/TermProject/dataset/Term_Dataset/train\n",
            "torch.Size([4, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_img_list(series, root_path) :\n",
        "    # series : data['file_name']\n",
        "    # root_path : 이미지 파일들이 존재하는 디렉토리 경로 ('./dataset/train/')\n",
        "    # return : (28,28,1) 형태의 array들이 담긴 list\n",
        "    \n",
        "    reshaped_image_list = []\n",
        "\n",
        "    for file_name in series :\n",
        "        image_path = '/content/drive/MyDrive/TermProject/dataset/Term_Dataset/train/' + file_name\n",
        "        image = Image.open(image_path)\n",
        "        image_array = np.array(image)\n",
        "        reshaped_image = transforms.Compose([\n",
        "            transforms.Resize((255, 255)),\n",
        "            transforms.ToTensor()\n",
        "        ]) #reshape\n",
        "        reshaped_image_list.append(reshaped_image)\n",
        "        # 넘파이 배열을 읽어오는 것에서 오류\n",
        "        \n",
        "    return reshaped_image_list"
      ],
      "metadata": {
        "id": "l4Qj7AkKq4GA"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform(mode='train'):\n",
        "    # Data Augmentation\n",
        "    # 마가리따님의 '파이토치 데이터 증강법 (점수:0.835)' 참고 : https://dacon.io/competitions/official/235838/codeshare/3734?page=1&dtype=recent\n",
        "    \n",
        "    t = list()\n",
        "    t.append(transforms.ToTensor())\n",
        "    \n",
        "    if mode == 'train':\n",
        "        t.append(transforms.RandomAffine(degrees=10, translate=(0.1,0.1)))\n",
        "\n",
        "    t.append(transforms.Normalize(mean=(.5),std=(.5)))\n",
        "    \n",
        "    return transforms.Compose(t)"
      ],
      "metadata": {
        "id": "tj8wiv04q74u"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmented Image 확인\n",
        "#sample이라 신경 안써도 될거 같다\n",
        "sample_transform = get_transform()\n",
        "sample_array = np.array(sample_image)\n",
        "\n",
        "nrows, ncols = 5,5\n",
        "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5,5))\n",
        "\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        sample_augmented_image = sample_transform(sample_array).reshape(32, 32)\n",
        "        ax[i][j].imshow(sample_augmented_image)\n",
        "        ax[i][j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_zxKcrlerAQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, mode, img_list, label=None):\n",
        "        self.mode = mode #train or test\n",
        "        self.transform = get_transform(mode)\n",
        "        self.img_list = img_list\n",
        "        self.label = label # 정답값(train)\n",
        "        self.transformed_img_list = list(map(self.transform, self.img_list))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        x_data = self.transformed_img_list[i]\n",
        "\n",
        "        if self.mode == 'train' :\n",
        "            return {\n",
        "              'X': x_data,\n",
        "              'Y': torch.tensor(self.label[i], dtype=torch.long)\n",
        "            }\n",
        "        else :\n",
        "            return {'X': x_data}"
      ],
      "metadata": {
        "id": "R-yi7SxmsCxV"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(x, y, root_path, mode='train') :\n",
        "    shuffle = True if mode == 'train' else False\n",
        "    img_list = get_img_list(x, root_path)\n",
        "    dataset = CustomDataset(mode=mode, img_list=img_list, label=y)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "    total_batch = math.ceil(len(dataset)/batch_size)\n",
        "\n",
        "    return dataloader, total_batch"
      ],
      "metadata": {
        "id": "vv8zJQO8rHf2"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫번째층\n",
        "        # ImgIn shape=(batch_size, 28, 28, 2)\n",
        "        #    Conv     -> (batch_size, 28, 28, 16)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 16, kernel_size=3, stride=1, padding='same'),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(16),\n",
        "            torch.nn.Dropout(p=0.3))\n",
        "        \n",
        "        # 두번째층\n",
        "        # ImgIn shape=(batch_size, 28, 28, 16)\n",
        "        #    Conv      ->(batch_size, 28, 28, 32)\n",
        "        #    Pool      ->(batch_size, 9, 9, 32)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding='same'),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(32),\n",
        "            torch.nn.Conv2d(32, 32, kernel_size=5, stride=1, padding='same'),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(32),\n",
        "            torch.nn.Conv2d(32, 32, kernel_size=5, stride=1, padding='same'),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(32),\n",
        "            torch.nn.Conv2d(32, 32, kernel_size=5, stride=1, padding='same'),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(32),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=3),\n",
        "            torch.nn.Dropout(p=0.3))\n",
        "        \n",
        "        # 세번째층\n",
        "        # ImgIn shape=(batch_size, 9, 9, 32)\n",
        "        #    Conv      ->(batch_size, 9, 9, 64)\n",
        "        #    Pool      ->(batch_size, 3, 3, 64)        \n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding='same'),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(64),\n",
        "            torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding='same'),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(64),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=3),\n",
        "            torch.nn.Dropout(p=0.3))\n",
        "        \n",
        "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
        "        self.fc = torch.nn.Linear(3*3*64, 10, bias=True)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight) # fc 가중치 초기화\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)   # Flatten\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "hlUlzqiK3usw"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    # 참고: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
        "    \n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='./weight', k_num=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.k_num = k_num\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "#             print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path + f'/best_{k_num}.pt')\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "AW6awCFm3xzP"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "OZZfcVL-30Be"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/drive/MyDrive/TermProject/dataset/Term_Dataset/'\n",
        "batch_size = 64\n",
        "epochs = 2000\n",
        "learning_rate = 0.002\n",
        "save_path = '/content/drive/MyDrive/TermProject/dataset/Term_Dataset/val_data_emp.csv'\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
        "                                                    lr_lambda=lambda epoch: 0.95 ** epoch,\n",
        "                                                    last_epoch=-1,\n",
        "                                                    verbose=False)"
      ],
      "metadata": {
        "id": "VdwlTH4d32Xo"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Validation\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "k_num = 0\n",
        "\n",
        "for train_index, valid_index in skf.split(train['file_name'], train['class']) :\n",
        "    model = CNN().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    k_num += 1\n",
        "    early_stopping = EarlyStopping(patience = 300, verbose = True, path = save_path, k_num = k_num)\n",
        "    \n",
        "    x_train = train['file_name'][train_index].reset_index(drop=True)\n",
        "    x_valid = train['file_name'][valid_index].reset_index(drop=True)\n",
        "    y_train = train['class'][train_index].reset_index(drop=True)\n",
        "    y_valid = train['class'][valid_index].reset_index(drop=True)\n",
        "\n",
        "    train_dataloader, train_total_batch = get_dataloader(x_train, y_train, root_path + 'train/', mode='train')\n",
        "    valid_dataloader, valid_total_batch = get_dataloader(x_valid, y_valid, root_path + 'val/', mode='train')\n",
        "    \n",
        "    for epoch in tqdm(range(epochs)) :\n",
        "        train_avg_cost, valid_avg_cost = 0, 0\n",
        "\n",
        "        for batch in train_dataloader :\n",
        "            train_X = batch['X'].to(device)\n",
        "            train_Y = batch['Y'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            hypothesis = model(train_X)\n",
        "            cost = criterion(hypothesis, train_Y)\n",
        "            cost.backward()\n",
        "            optimizer.step()\n",
        "            train_avg_cost += cost / train_total_batch\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        model.eval()\n",
        "        for batch in valid_dataloader :\n",
        "            valid_X = batch['X'].to(device)\n",
        "            valid_Y = batch['Y'].to(device)\n",
        "\n",
        "            with torch.no_grad() :\n",
        "                hypothesis = model(valid_X)\n",
        "                cost = criterion(hypothesis, valid_Y)\n",
        "                valid_avg_cost += cost / valid_total_batch        \n",
        "\n",
        "        early_stopping(float(valid_avg_cost), model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping!!\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "1LstLjcV4rle",
        "outputId": "09529a29-dede-458e-a204-521a8e66e223"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-b30aee2240ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_total_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_total_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'val/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-05c3f329a5f7>\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(x, y, root_path, mode)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-91-38791e812f95>\u001b[0m in \u001b[0;36mget_img_list\u001b[0;34m(series, root_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         ]) #reshape\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mPIL_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#        reshaped_image_list.append(reshaped_image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2702\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m     \"\"\"\n\u001b[0;32m-> 2704\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Compose' object has no attribute '__array_interface__'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_root_path = ''\n",
        "test_dataloader, test_total_batch = get_dataloader(test['file_name'], None, root_path=test_root_path, mode='test')"
      ],
      "metadata": {
        "id": "SYcmcS-l7o6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = torch.tensor([[0]*10]*len(test), dtype=torch.float)\n",
        "\n",
        "for weight in weigh_path_list :\n",
        "    model.load_state_dict(torch.load(weight))\n",
        "    model.eval()\n",
        "    preds_n = []\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        X = batch['X'].to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(X)\n",
        "            preds_n += list(pred)\n",
        "    \n",
        "    for i in range(len(test)) :\n",
        "        preds[i] += preds_n[i].cpu() \n",
        "        \n",
        "preds = torch.argmax(preds, axis=-1)"
      ],
      "metadata": {
        "id": "Rey2L3eG7raU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv('')"
      ],
      "metadata": {
        "id": "URbKyRgN7s33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub['class'] = preds"
      ],
      "metadata": {
        "id": "4kUoC_4G7tp9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}